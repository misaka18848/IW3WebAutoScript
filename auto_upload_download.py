import os
import time
import requests
import json
import shutil
from datetime import datetime
from pathlib import Path
import schedule
import logging
from urllib.parse import urljoin, quote
from urllib3.util.retry import Retry
import re
import sys
import io
import subprocess
# å¼ºåˆ¶ stdout å’Œ stderr ä½¿ç”¨ UTF-8 ç¼–ç 
if sys.stdout:
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
if sys.stderr:
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# åŒæ—¶è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¯é€‰ï¼‰
os.environ['PYTHONIOENCODING'] = 'utf-8'
# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('auto_upload_download.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class AutoUploadDownload:
    def __init__(self, config_file='auto_config.json'):
        self.config_file = config_file
        self.config = {
            'website_url': 'http://localhost:5000',  # æ‚¨çš„ç½‘ç«™åœ°å€
            'check_interval_minutes': 30,  # æ£€æŸ¥é—´éš”ï¼ˆåˆ†é’Ÿï¼‰
            'download_check_interval_minutes': 30,  # ä¸‹è½½æ£€æŸ¥é—´éš”ï¼ˆåˆ†é’Ÿï¼‰
            'folders_to_monitor': [
                {
                    'path': 'D:/videos',  # ç›‘æ§çš„æ–‡ä»¶å¤¹è·¯å¾„
                    'additional_args': ''  # é¢„è®¾å‚æ•°
                }
            ],
            'history_file': 'upload_history.json',  # å†å²è®°å½•æ–‡ä»¶
            'max_retries': 5,  # æœ€å¤§é‡è¯•æ¬¡æ•°
            'retry_delay': 10  # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
        }
        
        # åŠ è½½é…ç½®
        self.load_config()
        
        # åŠ è½½å†å²è®°å½•
        self.history = self.load_history()
        
        # ç¡®ä¿å†å²æ–‡ä»¶å¤¹å­˜åœ¨
        history_dir = os.path.dirname(self.config['history_file'])
        if history_dir:
            os.makedirs(history_dir, exist_ok=True)
    
    def load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            if os.path.exists(self.config_file):
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    loaded_config = json.load(f)
                    # åˆå¹¶é…ç½®ï¼Œä¿ç•™é»˜è®¤å€¼
                    for key, value in loaded_config.items():
                        self.config[key] = value
                logger.info(f"å·²åŠ è½½é…ç½®æ–‡ä»¶: {self.config_file}")
            else:
                # åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
                self.save_config()
                logger.info(f"åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶: {self.config_file}")
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    
    def save_config(self):
        """ä¿å­˜é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(self.config, f, indent=4, ensure_ascii=False)
            logger.info(f"é…ç½®å·²ä¿å­˜åˆ°: {self.config_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    
    def load_history(self):
        """åŠ è½½å†å²è®°å½•"""
        try:
            if os.path.exists(self.config['history_file']):
                with open(self.config['history_file'], 'r', encoding='utf-8') as f:
                    history = json.load(f)
                    # ç¡®ä¿æ‰€æœ‰å¿…è¦çš„é”®éƒ½å­˜åœ¨
                    if 'uploaded_files' not in history:
                        history['uploaded_files'] = {}
                    if 'downloaded_files' not in history:
                        history['downloaded_files'] = {}
                    return history
            else:
                # åˆ›å»ºé»˜è®¤å†å²è®°å½•
                history = {
                    'uploaded_files': {},  # {full_path: {'uploaded_at': timestamp, 'url': url, 'additional_args': args}}
                    'downloaded_files': {}  # {full_path: {'downloaded_at': timestamp, 'target_folder': folder}}
                }
                self.save_history(history)
                return history
        except Exception as e:
            logger.error(f"åŠ è½½å†å²è®°å½•å¤±è´¥: {e}")
            return {
                'uploaded_files': {},
                'downloaded_files': {}
            }
    
    def save_history(self, history=None):
        """ä¿å­˜å†å²è®°å½•"""
        try:
            if history is None:
                history = self.history
            with open(self.config['history_file'], 'w', encoding='utf-8') as f:
                json.dump(history, f, indent=4, ensure_ascii=False)
            logger.info(f"å†å²è®°å½•å·²ä¿å­˜åˆ°: {self.config['history_file']}")
        except Exception as e:
            logger.error(f"ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")
    
    def get_file_hash(self, file_path):
        """ç”Ÿæˆæ–‡ä»¶çš„å”¯ä¸€æ ‡è¯†ï¼ˆåŸºäºæ–‡ä»¶è·¯å¾„å’Œå¤§å°ï¼‰"""
        try:
            stat = os.stat(file_path)
            file_info = f"{file_path}|{stat.st_size}|{stat.st_mtime}"
            import hashlib
            return hashlib.md5(file_info.encode('utf-8')).hexdigest()
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ–‡ä»¶å“ˆå¸Œå¤±è´¥ {file_path}: {e}")
            return None
    
    def is_file_processed(self, file_path):
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç»å¤„ç†è¿‡"""
        file_hash = self.get_file_hash(file_path)
        if not file_hash:
            return False
            
        # æ£€æŸ¥æ˜¯å¦å·²ç»ä¸Šä¼ è¿‡
        for uploaded_info in self.history['uploaded_files'].values():
            if uploaded_info.get('file_hash') == file_hash:
                return True
        return False
    
    def find_new_videos(self):
        """æŸ¥æ‰¾æ–°çš„è§†é¢‘æ–‡ä»¶ï¼ˆä»…é™ç›‘æ§æ–‡ä»¶å¤¹æ ¹ç›®å½•ï¼Œä¸é€’å½’ï¼‰"""
        new_videos = []
        
        for folder_info in self.config['folders_to_monitor']:
            folder_path = folder_info['path']
            if not os.path.exists(folder_path):
                logger.warning(f"ç›‘æ§æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}")
                continue
                
            try:
                # æ”¯æŒçš„è§†é¢‘æ ¼å¼
                video_extensions = {'.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm'}
                
                # ---  å…³é”®ä¿®æ”¹ï¼šåªéå†æ ¹ç›®å½•ï¼Œä¸é€’å½’ ---
                # æ–¹æ³•ä¸€ï¼šä½¿ç”¨ os.scandir() (æ¨èï¼Œæ•ˆç‡é«˜)
                with os.scandir(folder_path) as entries:
                    for entry in entries:
                        # åªå¤„ç†æ–‡ä»¶ï¼Œå¿½ç•¥ç›®å½•
                        if entry.is_file():
                            file_ext = os.path.splitext(entry.name.lower())[1]
                            if file_ext in video_extensions:
                                file_path = entry.path # entry.path åŒ…å«å®Œæ•´è·¯å¾„
                                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç»å¤„ç†è¿‡
                                if not self.is_file_processed(file_path):
                                    new_videos.append({
                                        'path': file_path,
                                        'folder_info': folder_info,
                                        'target_folder': os.path.dirname(file_path)  # ç›®æ ‡æ–‡ä»¶å¤¹æ˜¯åŸæ–‡ä»¶å¤¹
                                    })
                                else:
                                    logger.debug(f"è·³è¿‡å·²å¤„ç†çš„æ–‡ä»¶: {file_path}")

            except Exception as e:
                logger.error(f"æ‰«ææ–‡ä»¶å¤¹å¤±è´¥ {folder_path}: {e}")
        
        return new_videos
    
    def upload_video(self, video_path, additional_args, target_folder):
        """ä½¿ç”¨åˆ†å—ä¸Šä¼ æ–¹å¼ä¸Šä¼ å¤§è§†é¢‘æ–‡ä»¶ï¼Œé€‚é…å½“å‰åç«¯ session_id æœºåˆ¶"""
        session = requests.Session()
        
        # ç¡®ä¿ç›®æ ‡VRæ–‡ä»¶å¤¹å­˜åœ¨ (å¦‚æœæ‚¨çš„è„šæœ¬é€»è¾‘è¿˜éœ€è¦è¿™ä¸ª)
        vr_folder = os.path.join(target_folder, 'VR')
        os.makedirs(vr_folder, exist_ok=True)
        
        filename = os.path.basename(video_path)
        file_size = os.path.getsize(video_path)
        chunk_size = 10 * 1024 * 1024  # 10MB æ¯å—ï¼ˆå¯é…ç½®ï¼‰
        total_chunks = (file_size // chunk_size) + (1 if file_size % chunk_size else 0)
        
        logger.info(f"å‡†å¤‡ä¸Šä¼ å¤§æ–‡ä»¶: {filename}")
        logger.info(f"å¤§å°: {file_size / (1024*1024):.1f}MB | åˆ†å—æ•°: {total_chunks} | å—å¤§å°: {chunk_size / 1024:.1f}KB")
        
        # === åˆ†å—ä¸Šä¼ é€»è¾‘å¼€å§‹ ===
        # ğŸŸ¡ å…³é”®ï¼šåˆå§‹åŒ– session_id ä¸º Noneï¼Œé¦–æ¬¡ä¸Šä¼ æ—¶ä¸ä¼šå‘é€
        current_session_id = None 
        
        try:
            with open(video_path, 'rb') as f:
                for chunk_index in range(total_chunks):
                    # è®¡ç®—å½“å‰å—
                    f.seek(chunk_index * chunk_size)
                    chunk_data = f.read(chunk_size)
                    
                    # å‡†å¤‡åˆ†å—æ•°æ®
                    files = {
                        'chunk': ('chunk', chunk_data) # æ–‡ä»¶å—æ•°æ®
                    }
                    data = {
                        'filename': filename,
                        'chunk_index': chunk_index,
                        'total_chunks': total_chunks,
                        'additional_args': additional_args
                        # 'session_id': current_session_id # åœ¨ä¸‹é¢çš„æ¡ä»¶ä¸­æ·»åŠ 
                    }
                    
                    # ğŸŸ¡ å…³é”®ï¼šå¦‚æœå·²æœ‰ session_idï¼Œåˆ™æ·»åŠ åˆ° data ä¸­
                    if current_session_id is not None:
                        data['session_id'] = current_session_id
                    
                    # å¸¦é‡è¯•çš„ä¸Šä¼ 
                    for attempt in range(self.config['max_retries']):
                        try:
                            logger.debug(f"ä¸Šä¼ å— {chunk_index + 1}/{total_chunks} (å°è¯• {attempt + 1})")
                            
                            response = session.post(
                                f"{self.config['website_url']}/upload",  # ä½¿ç”¨ /upload æ¥å£
                                files=files,
                                data=data,
                                timeout=300  # æ¯å—ä¸Šä¼ è¶…æ—¶5åˆ†é’Ÿ
                            )
                            
                            if response.status_code == 200:
                                try:
                                    result = response.json()
                                except requests.exceptions.JSONDecodeError as e:
                                    logger.error(f"è§£ææœåŠ¡å™¨å“åº”å¤±è´¥ (HTTP 200): {e}")
                                    logger.error(f"å“åº”å†…å®¹: {response.text}")
                                    # å¦‚æœè§£æå¤±è´¥ï¼Œæœ¬æ¬¡å°è¯•è§†ä¸ºå¤±è´¥ï¼Œè¿›è¡Œé‡è¯•
                                    continue # è·³å‡ºæœ¬æ¬¡ attempt çš„æˆåŠŸå¤„ç†ï¼Œè¿›å…¥ä¸‹ä¸€æ¬¡é‡è¯•æˆ–å¾ªç¯

                                # ğŸŸ¡ å…³é”®ï¼šæ£€æŸ¥å“åº”æ˜¯å¦åŒ…å«æ–°çš„ session_id (é¦–æ¬¡ä¸Šä¼ æˆ–åç»­ä¸Šä¼ éƒ½ä¼šè¿”å›)
                                if 'session_id' in result:
                                    # ğŸŸ¡ å…³é”®ï¼šæ›´æ–°å½“å‰çš„ session_idï¼Œç”¨äºä¸‹ä¸€æ¬¡ä¸Šä¼ 
                                    # å³ä½¿æ˜¯ç¬¬ä¸€æ¬¡ï¼Œä¹Ÿä¼šä»æœåŠ¡å™¨è·å–åˆ°æ–°çš„ session_id
                                    current_session_id = result['session_id']
                                    logger.debug(f"è·å–/æ›´æ–° session_id: {current_session_id}")

                                # ğŸŸ¡ å…³é”®ï¼šæ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆçš„åˆå¹¶æˆåŠŸæ¶ˆæ¯
                                if result.get('message') == 'ä¸Šä¼ å¹¶åˆå¹¶å®Œæˆï¼Œå·²åŠ å…¥è½¬æ¢é˜Ÿåˆ—':
                                    logger.info(f" æ–‡ä»¶ '{filename}' ä¸Šä¼ ã€åˆå¹¶æˆåŠŸï¼Œå¹¶å·²åŠ å…¥è½¬æ¢é˜Ÿåˆ—ï¼")
                                    # ğŸŸ¡ å…³é”®ï¼šè®°å½•åˆ°å†å²ï¼ˆçŠ¶æ€ä¸º uploadedï¼‰
                                    file_hash = self.get_file_hash(video_path)
                                    self.history['uploaded_files'][video_path] = {
                                        'uploaded_at': datetime.now().isoformat(),
                                        'url': self.config['website_url'],
                                        'additional_args': additional_args,
                                        'target_folder': target_folder,
                                        'file_hash': file_hash,
                                        'status': 'uploaded', # ç­‰å¾… check_conversion_status ä¸‹è½½
                                        # å¯é€‰ï¼šå­˜å‚¨ session_id ä»¥ä¾¿åç»­è¿½è¸ª
                                        'session_id': current_session_id 
                                    }
                                    self.save_history()
                                    return True # ä¸Šä¼ å’Œåˆå¹¶æˆåŠŸï¼Œç›´æ¥è¿”å›

                                # å¦‚æœä¸æ˜¯æœ€ç»ˆæˆåŠŸï¼Œä½†å—ä¸Šä¼ æˆåŠŸ (ä¾‹å¦‚ 'å— X/Y ä¸Šä¼ æˆåŠŸ')
                                if 'message' in result and ('ä¸Šä¼ æˆåŠŸ' in result['message'] or 'ä¸Šä¼ å®Œæˆ' in result['message']):
                                    logger.info(f" å— {chunk_index + 1}/{total_chunks} ä¸Šä¼ æˆåŠŸ: {result.get('message', 'OK')}")
                                    break # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯ï¼Œå¤„ç†ä¸‹ä¸€ä¸ªå—
                                else:
                                    # æœåŠ¡å™¨è¿”å›äº† 200 ä½†æ¶ˆæ¯ä¸æ˜¯é¢„æœŸçš„æˆåŠŸï¼Œè§†ä¸ºå¤±è´¥
                                    logger.warning(f" å— {chunk_index} ä¸Šä¼ æœªæˆåŠŸ (HTTP 200 ä½†æ¶ˆæ¯å¼‚å¸¸): {result}")
                                    
                            else:
                                logger.warning(f" å— {chunk_index} ä¸Šä¼ å¤±è´¥ (HTTP {response.status_code}): {response.text}")
                                
                        except Exception as e:
                            logger.warning(f" å— {chunk_index} ä¸Šä¼ å¼‚å¸¸ (å°è¯• {attempt + 1}): {e}")
                        
                        # é‡è¯•å‰ç­‰å¾…
                        if attempt < self.config['max_retries'] - 1:
                            time.sleep(self.config['retry_delay'])
                    else:
                        # æ‰€æœ‰é‡è¯•å‡å¤±è´¥
                        logger.error(f" å— {chunk_index} è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä¸Šä¼ ä¸­æ–­")
                        return False  # æ•´ä½“ä¸Šä¼ å¤±è´¥
                
                # === æ³¨æ„ï¼šæ­£å¸¸æƒ…å†µä¸‹ï¼Œå¾ªç¯ç»“æŸå‰åº”è¯¥å› ä¸ºæœ€ç»ˆæˆåŠŸæ¶ˆæ¯è€Œ return True ===
                # å¦‚æœä»£ç æ‰§è¡Œåˆ°è¿™é‡Œï¼Œæ„å‘³ç€æ‰€æœ‰åˆ†å—éƒ½ä¸Šä¼ äº†ï¼Œä½†æ²¡æœ‰æ”¶åˆ°æœ€ç»ˆçš„åˆå¹¶æˆåŠŸæ¶ˆæ¯
                # è¿™é€šå¸¸ä¸åº”è¯¥å‘ç”Ÿï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜å¯¼è‡´æœ€åçš„å“åº”æ²¡æ”¶åˆ°
                logger.warning(f"æ‰€æœ‰ {total_chunks} ä¸ªåˆ†å—ä¸Šä¼ å®Œæˆï¼Œä½†æœªæ”¶åˆ°æœ€ç»ˆåˆå¹¶æˆåŠŸç¡®è®¤ã€‚å¯èƒ½éœ€è¦æ‰‹åŠ¨æ£€æŸ¥æˆ–é‡è¯•ã€‚")
                # æ‚¨å¯ä»¥é€‰æ‹©åœ¨è¿™é‡Œè¿”å› Falseï¼Œæˆ–è€…å°è¯•æ·»åŠ ä¸€ä¸ªé€»è¾‘å»è½®è¯¢çŠ¶æ€
                # ä½†æ ¹æ®ç°æœ‰åç«¯é€»è¾‘ï¼Œè¿™åº”è¯¥å¾ˆå°‘è§ã€‚
                return False
                
        except Exception as e:
            logger.error(f"åˆ†å—ä¸Šä¼ è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯ {filename}: {e}")
            return False
    
    def check_conversion_status(self):
        """æ£€æŸ¥è½¬æ¢çŠ¶æ€å¹¶ä¸‹è½½å®Œæˆçš„æ–‡ä»¶ï¼ˆé€‚é…æ–°ç‰ˆç½‘ç«™ API - è¿”å›å­—ç¬¦ä¸²åˆ—è¡¨ï¼‰"""
        session = requests.Session()
        
        try:
            api_url = f"{self.config['website_url']}/api/status"
            logger.debug(f"è¯·æ±‚çŠ¶æ€æ¥å£: {api_url}")
            
            response = session.get(api_url, timeout=20)
            if response.status_code != 200:
                logger.warning(f"è·å–çŠ¶æ€å¤±è´¥: {response.status_code} - {response.text}")
                return
            
            try:
                data = response.json()
            except json.JSONDecodeError as e:
                logger.error(f"å“åº”ä¸æ˜¯æœ‰æ•ˆçš„JSON: {e}")
                return

            # æå–å·²è½¬æ¢æ–‡ä»¶åˆ—è¡¨
            # å…³é”®ï¼šåç«¯è¿”å›çš„æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œå¦‚ ["file1.mp4", "file2.mp4"]
            converted_files = data.get('converted_files', [])
            if not converted_files:
                logger.info("æš‚æ— å·²è½¬æ¢çš„æ–‡ä»¶ã€‚")
                return

            logger.info(f"å‘ç° {len(converted_files)} ä¸ªå·²è½¬æ¢æ–‡ä»¶: {converted_files}")

            # å…³é”®ï¼šç›´æ¥éå†å­—ç¬¦ä¸²åˆ—è¡¨ä¸­çš„æ–‡ä»¶å
            for filename in converted_files:
                # ç¡®ä¿æ–‡ä»¶åå­˜åœ¨ä¸”ä¸ä¸ºç©º
                if not filename or not isinstance(filename, str):
                    continue

                # åœ¨ä¸Šä¼ å†å²ä¸­æŸ¥æ‰¾åŒ¹é…çš„åŸå§‹æ–‡ä»¶
                matched = False
                for uploaded_path, info in self.history['uploaded_files'].items():
                    # æ£€æŸ¥çŠ¶æ€ä¸º 'uploaded' ä¸”åŸå§‹æ–‡ä»¶ååŒ¹é…
                    if (info.get('status') == 'uploaded' and 
                        os.path.basename(uploaded_path) == filename):
                        
                        # æ‰¾åˆ°åŒ¹é…ï¼Œå¼€å§‹ä¸‹è½½
                        if self.download_converted_file(session, filename, info['target_folder']):
                            # æ›´æ–°ä¸Šä¼ å†å²ä¸­çš„çŠ¶æ€
                            info['status'] = 'downloaded'
                            info['downloaded_at'] = datetime.now().isoformat()
                            
                            # å°†ä¿¡æ¯æ·»åŠ åˆ°ä¸‹è½½å†å²
                            self.history['downloaded_files'][uploaded_path] = {
                                'downloaded_at': datetime.now().isoformat(),
                                'target_folder': info['target_folder'],
                                'original_filename': filename
                            }
                            logger.info(f"æ–‡ä»¶å·²ä¸‹è½½å¹¶è®°å½•: {filename}")
                        
                        matched = True
                        break # æ‰¾åˆ°åŒ¹é…é¡¹åè·³å‡ºå¾ªç¯

                if not matched:
                    logger.warning(f"æœªæ‰¾åˆ°ä¸Šä¼ è®°å½•çš„å·²è½¬æ¢æ–‡ä»¶: {filename}")

            # ä¿å­˜æ›´æ–°åçš„å†å²è®°å½•
            self.save_history()

        except requests.exceptions.RequestException as e:
            logger.error(f"è¯·æ±‚ç½‘ç«™çŠ¶æ€æ—¶å‘ç”Ÿç½‘ç»œé”™è¯¯: {e}")
        except Exception as e:
            logger.error(f"æ£€æŸ¥è½¬æ¢çŠ¶æ€æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
    
    def download_converted_file(self, session, filename, target_folder):
        """
        ä¸‹è½½è½¬æ¢å®Œæˆçš„æ–‡ä»¶ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œå¹¶æå–åŸå§‹è§†é¢‘å†…å°å­—å¹•ã€‚
        å‡è®¾æœåŠ¡ç«¯ä¸ä¿®æ”¹æ–‡ä»¶åï¼ŒåŸå§‹è§†é¢‘ä½äº target_folder æ ¹ç›®å½•ã€‚
        """
        try:
            encoded_filename = quote(filename, safe='')
            download_url = f"{self.config['website_url']}/download/{encoded_filename}"
            
            vr_folder = os.path.join(target_folder, 'VR')
            os.makedirs(vr_folder, exist_ok=True)
            target_path = os.path.join(vr_folder, filename)
            
            logger.info(f"å¼€å§‹ä¸‹è½½: {filename} -> {target_path}")
            
            # --- æ–­ç‚¹ç»­ä¼ é€»è¾‘ ---
            resume_byte_pos = 0
            if os.path.exists(target_path):
                resume_byte_pos = os.path.getsize(target_path)
                if resume_byte_pos > 0:
                    logger.info(f"æ£€æµ‹åˆ°éƒ¨åˆ†ä¸‹è½½çš„æ–‡ä»¶ï¼Œå¤§å°: {resume_byte_pos} å­—èŠ‚ï¼Œå°è¯•ç»­ä¼ ...")
                else:
                    logger.info(f"æ£€æµ‹åˆ°ç©ºæ–‡ä»¶ï¼Œé‡æ–°å¼€å§‹ä¸‹è½½...")
                    resume_byte_pos = 0

            max_retries = self.config.get('max_download_retries', 3)

            for attempt in range(max_retries + 1):
                try:
                    headers = {}
                    if resume_byte_pos > 0:
                        headers['Range'] = f'bytes={resume_byte_pos}-'
                    
                    response = session.get(download_url, headers=headers, stream=True, timeout=(30, 7200), allow_redirects=True)

                    if response.status_code == 200:
                        if resume_byte_pos > 0:
                            logger.warning("æœåŠ¡å™¨ä¸æ”¯æŒ Range è¯·æ±‚ï¼Œå°†é‡æ–°å¼€å§‹ä¸‹è½½ã€‚")
                            os.remove(target_path)
                            resume_byte_pos = 0
                            logger.info("å°†è¦†ç›–ç°æœ‰æ–‡ä»¶é‡æ–°ä¸‹è½½ã€‚")
                        file_mode = 'wb'
                        expected_status = 200
                    elif response.status_code == 206:
                        if resume_byte_pos == 0:
                            logger.warning("æ”¶åˆ° 206 çŠ¶æ€ç ä½†æœªè¯·æ±‚ Rangeï¼Œè¡Œä¸ºå¼‚å¸¸ã€‚")
                        file_mode = 'ab'
                        expected_status = 206
                    else:
                        logger.error(f"ä¸‹è½½å¤±è´¥ (HTTP {response.status_code}): {filename}")
                        if 400 <= response.status_code < 500:
                            return False
                        if attempt < max_retries:
                            logger.warning(f"HTTP é”™è¯¯ï¼Œå‡†å¤‡é‡è¯•...")
                            time.sleep(self.config.get('retry_delay', 10))
                            continue
                        else:
                            return False

                    if response.status_code != expected_status:
                        logger.error(f"é¢„æœŸçŠ¶æ€ç  {expected_status}ï¼Œå®é™…ä¸º {response.status_code}")
                        if attempt < max_retries:
                            time.sleep(self.config.get('retry_delay', 10))
                            continue
                        else:
                            return False

                    with open(target_path, file_mode) as f:
                        bytes_downloaded = 0
                        for chunk in response.iter_content(chunk_size=8192):
                            if chunk:
                                f.write(chunk)
                                bytes_downloaded += len(chunk)
                    
                    logger.info(f"ä¸‹è½½å®Œæˆ: {filename} (æœ¬æ¬¡ä¼ è¾“ {bytes_downloaded} å­—èŠ‚)")
                    
                    # âœ…âœ…âœ… === æ–°å¢åŠŸèƒ½ï¼šæå–åŸå§‹è§†é¢‘å†…å°å­—å¹• ===
                    # 1. ç›´æ¥æ„å»ºåŸå§‹è§†é¢‘è·¯å¾„
                    # å› ä¸ºæœåŠ¡ç«¯ä¸ä¿®æ”¹æ–‡ä»¶åï¼ŒåŸå§‹è§†é¢‘å°±åœ¨ target_folder æ ¹ç›®å½•ä¸‹
                    original_video_path = os.path.join(target_folder, filename)
                    
                    if not os.path.exists(original_video_path):
                        logger.warning(f"åŸå§‹è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•æå–å­—å¹•: {original_video_path}")
                        return True  # ä¸‹è½½æˆåŠŸï¼Œå­—å¹•æå–å¤±è´¥ä¸å½±å“ä¸»æµç¨‹

                    # 2. æ„å»º ffmpeg è·¯å¾„
                    script_dir = Path(__file__).parent
                    ffmpeg_path = script_dir / "bin" / "ffmpeg.exe"
                    if not ffmpeg_path.exists():
                        logger.warning(f"ffmpeg æœªæ‰¾åˆ°: {ffmpeg_path}ï¼Œè·³è¿‡å­—å¹•æå–")
                        return True

                    # 3. ä½¿ç”¨ ffprobe åˆ†æå­—å¹•æµ
                    try:
                        import subprocess
                        cmd_probe = [
                            str(ffmpeg_path), '-v', 'error', '-select_streams', 's', 
                            '-show_entries', 'stream=index:stream=codec_type', 
                            '-of', 'json', original_video_path
                        ]
                        result = subprocess.run(cmd_probe, capture_output=True, text=True, check=False)
                        
                        if result.returncode != 0:
                            logger.debug(f"ffprobe åˆ†æå­—å¹•æµå¤±è´¥: {result.stderr}")
                            return True

                        try:
                            streams_info = json.loads(result.stdout)
                            text_subtitle_streams = []
                            for stream in streams_info.get('streams', []):
                                if (stream.get('codec_type') == 'subtitle' and 
                                    stream.get('codec_name') in ['srt', 'ass', 'subrip', 'text']):
                                    text_subtitle_streams.append(stream)
                            
                            if not text_subtitle_streams:
                                logger.info(f"åŸå§‹è§†é¢‘æ— å†…å°æ–‡æœ¬å­—å¹•ï¼Œè·³è¿‡æå–: {os.path.basename(original_video_path)}")
                                return True

                            # æå–ç¬¬ä¸€ä¸ªæ–‡æœ¬å­—å¹•æµ
                            target_subtitle_path = os.path.join(vr_folder, f"{Path(filename).stem}.srt")
                            if os.path.exists(target_subtitle_path):
                                logger.info(f"å­—å¹•æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡æå–: {target_subtitle_path}")
                                return True

                            stream_index = text_subtitle_streams[0]['index']
                            cmd_extract = [
                                str(ffmpeg_path), '-i', original_video_path, 
                                '-map', f'0:{stream_index}', '-c:s', 'srt', 
                                '-y', target_subtitle_path
                            ]
                            
                            logger.info(f"æ­£åœ¨æå–å­—å¹•æµ {stream_index} -> {target_subtitle_path}")
                            result_extract = subprocess.run(cmd_extract, capture_output=True, text=True, check=False)
                            
                            if result_extract.returncode == 0:
                                logger.info(f"âœ… å­—å¹•æå–æˆåŠŸ: {target_subtitle_path}")
                            else:
                                logger.warning(f"âš ï¸ å­—å¹•æå–å¤±è´¥ (ffmpeg): {result_extract.stderr}")
                            
                        except json.JSONDecodeError as e:
                            logger.error(f"è§£æ ffprobe è¾“å‡ºå¤±è´¥: {e}")
                            
                    except Exception as e:
                        logger.error(f"æ‰§è¡Œ ffmpeg æå–å­—å¹•æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    
                    # âœ…âœ…âœ… === æ–°å¢åŠŸèƒ½ç»“æŸ ===
                    
                    return True

                except requests.exceptions.RequestException as e:
                    logger.warning(f"è¯·æ±‚å¼‚å¸¸ (ä¸‹è½½ {filename}) (å°è¯• {attempt + 1}/{max_retries + 1}): {e}")
                    if attempt < max_retries:
                        time.sleep(self.config.get('retry_delay', 10))
                    else:
                        logger.error(f"ä¸‹è½½ {filename} è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œå¤±è´¥ã€‚")
                        return False
                except OSError as e:
                    logger.error(f"æ–‡ä»¶ç³»ç»Ÿé”™è¯¯ (ä¸‹è½½ {filename}): {e}")
                    return False
                except Exception as e:
                    logger.error(f"ä¸‹è½½æ–‡ä»¶å¤±è´¥ {filename}: {e}")
                    return False

            return False
                
        except Exception as e:
            logger.error(f"ä¸‹è½½æ–‡ä»¶ {filename} å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            return False
    
    def run_once(self):
        """æ‰§è¡Œä¸€æ¬¡å®Œæ•´æµç¨‹"""
        logger.info("å¼€å§‹æ‰§è¡Œè‡ªåŠ¨åŒ–ä»»åŠ¡...")
        
        # 1. æŸ¥æ‰¾æ–°è§†é¢‘å¹¶ä¸Šä¼ 
        new_videos = self.find_new_videos()
        logger.info(f"æ‰¾åˆ° {len(new_videos)} ä¸ªæ–°è§†é¢‘")
        
        for video in new_videos:
            try:
                success = self.upload_video(
                    video['path'], 
                    video['folder_info']['additional_args'],
                    video['target_folder']
                )
                if success:
                    logger.info(f"æˆåŠŸä¸Šä¼ : {video['path']}")
                else:
                    logger.error(f"ä¸Šä¼ å¤±è´¥: {video['path']}")
            except Exception as e:
                logger.error(f"å¤„ç†è§†é¢‘å¤±è´¥ {video['path']}: {e}")
        
        # 2. æ£€æŸ¥å¹¶ä¸‹è½½å·²è½¬æ¢çš„æ–‡ä»¶
        self.check_conversion_status()
        
        logger.info("è‡ªåŠ¨åŒ–ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
    
    def start_scheduler(self):
        """å¯åŠ¨å®šæ—¶ä»»åŠ¡"""
        logger.info(f"å¯åŠ¨è‡ªåŠ¨åŒ–è„šæœ¬ï¼Œç›‘æ§é…ç½®: {self.config_file}")
        
        # æ¯30åˆ†é’Ÿæ£€æŸ¥æ–°è§†é¢‘
        schedule.every(self.config['check_interval_minutes']).minutes.do(self.run_once)
        
        # ä¹Ÿå¯ä»¥è®¾ç½®å…·ä½“æ—¶é—´ç‚¹
        # schedule.every().hour.at(":00").do(self.run_once)
        # schedule.every().hour.at(":30").do(self.run_once)
        
        logger.info(f"å·²è®¾ç½®å®šæ—¶ä»»åŠ¡: æ¯ {self.config['check_interval_minutes']} åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡")
        
        # ç«‹å³æ‰§è¡Œä¸€æ¬¡
        self.run_once()
        
        # å¼€å§‹å¾ªç¯
        while True:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡

def create_sample_config():
    """åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶"""
    config = {
        'website_url': 'http://localhost:5000',
        'check_interval_minutes': 30,
        'download_check_interval_minutes': 30,
        'folders_to_monitor': [
            {
                'path': 'D:/videos',
                'additional_args': ''
            },
            {
                'path': 'E:/movies',
                'additional_args': ''
            }
        ],
        'history_file': 'upload_history.json',
        'max_retries': 5,
        'retry_delay': 10
    }
    
    with open('auto_config.json', 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=4, ensure_ascii=False)
    
    print("å·²åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶ auto_config.json")
    print("è¯·æ ¹æ®æ‚¨çš„å®é™…æƒ…å†µä¿®æ”¹é…ç½®æ–‡ä»¶")

if __name__ == "__main__":
    # å¦‚æœæ²¡æœ‰é…ç½®æ–‡ä»¶ï¼Œåˆ›å»ºç¤ºä¾‹é…ç½®
    if not os.path.exists('auto_config.json'):
        create_sample_config()
    
    # åˆ›å»ºè‡ªåŠ¨åŒ–å®ä¾‹å¹¶å¯åŠ¨
    auto = AutoUploadDownload()
    auto.start_scheduler()